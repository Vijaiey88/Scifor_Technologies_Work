{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear regression"
      ],
      "metadata": {
        "id": "bXM_nzfvk7bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple linear regression is a statistical method used to model the relationship between two variables, where one variable (the independent variable)\n",
        "## is used to predict the value of another variable (the dependent variable) using a linear equation."
      ],
      "metadata": {
        "id": "oeAMEpSfX8cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZDbjyfjiXCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a0dd95-5cd9-4937-b415-d432dc11cdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values: [1.2 2.4 3.6 4.8 6. ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def linear_regression(X, y, learning_rate, epochs):\n",
        "    m, n = X.shape\n",
        "    weights = np.zeros(n)\n",
        "    cost_list = []\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        predictions = np.dot(X, weights)\n",
        "        error = predictions - y\n",
        "        gradient = np.dot(X.T, error) / m\n",
        "        weights -= learning_rate * gradient\n",
        "        cost = (1 / (2 * m)) * np.sum(error**2)\n",
        "        cost_list.append(cost)\n",
        "\n",
        "    return weights, cost_list\n",
        "\n",
        "\n",
        "def linear_regression_predict(X, weights):\n",
        "    predictions = np.dot(X, weights)\n",
        "    return predictions\n",
        "\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Training\n",
        "weights, _ = linear_regression(X, y, 0.01, 1000)\n",
        "\n",
        "# Prediction\n",
        "print(\"Predicted values:\", linear_regression_predict(X, weights))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Linear regression"
      ],
      "metadata": {
        "id": "4i6mpLkSHiVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Simple linear regression is a statistical method used to model the relationship between two variables, where two or more variables\n",
        "## (the independent variable) is used to predict the value of another variable (the dependent variable) using a linear equation."
      ],
      "metadata": {
        "id": "4GWn6SDWYFmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def multiple_linear_regression(X, y, learning_rate, epochs):\n",
        "    m, n = X.shape\n",
        "    weights = np.zeros(n)\n",
        "    cost_list = []\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        predictions = np.dot(X, weights)\n",
        "        error = predictions - y\n",
        "        gradient = np.dot(X.T, error) / m\n",
        "        weights -= learning_rate * gradient\n",
        "        cost = (1 / (2 * m)) * np.sum(error**2)\n",
        "        cost_list.append(cost)\n",
        "\n",
        "    return weights, cost_list\n",
        "\n",
        "\n",
        "def multiple_linear_regression_predict(X, weights):\n",
        "    predictions = np.dot(X, weights)\n",
        "    return predictions\n",
        "\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Training\n",
        "weights, _ = multiple_linear_regression(X, y, 0.01, 1000)\n",
        "\n",
        "# Prediction\n",
        "print(\"Predicted values:\", multiple_linear_regression_predict(X, weights))"
      ],
      "metadata": {
        "id": "hWmzyG5_FYiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e1af82-0187-41b6-e827-92d6eadab089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values: [2.22033819 3.04663132 3.87292446 4.69921759 5.52551072]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression"
      ],
      "metadata": {
        "id": "7j8yrPvKICUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " ## Logistic regression is a statistical method used for binary classification problems, where the target variable (or outcome)\n",
        " ## is categorical and has only two possible outcomes, typically denoted as 0 and 1."
      ],
      "metadata": {
        "id": "TcdkiRUFYYGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def logistic_regression(X, y, learning_rate, epochs):\n",
        "    m, n = X.shape\n",
        "    weights = np.zeros(n)\n",
        "    cost_list = []\n",
        "    for _ in range(epochs):\n",
        "        z = np.dot(X, weights)\n",
        "        probabilities = sigmoid(z)\n",
        "        error = probabilities - y\n",
        "        gradient = np.dot(X.T, error) / m\n",
        "        weights -= learning_rate * gradient\n",
        "        cost = -np.mean(y * np.log(probabilities) + (1 - y) * np.log(1 - probabilities))\n",
        "        cost_list.append(cost)\n",
        "    return weights, cost_list\n",
        "\n",
        "def predict(X, weights, threshold=0.5):\n",
        "    probabilities = sigmoid(np.dot(X, weights))\n",
        "    return (probabilities >= threshold).astype(int)\n",
        "\n",
        "\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
        "y = np.array([0, 0, 1, 1, 1])\n",
        "\n",
        "weights, _ = logistic_regression(X, y, learning_rate=0.01, epochs=1000)\n",
        "\n",
        "predictions = predict(X, weights)\n",
        "print(\"Predicted class labels:\", predictions)"
      ],
      "metadata": {
        "id": "uDYtOcVfefXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f019ede7-d12e-4078-dbc2-65452ea0c56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class labels: [1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Decision tree:\n",
        "\"\"\"A decision tree is a hierarchical tree-like structure where each internal node represents a decision based on the value of a feature,\n",
        "each branch represents the outcome of that decision, and each leaf node represents a class label or a numerical value\"\"\""
      ],
      "metadata": {
        "id": "1Cd2563BJDqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3f8932be-2527-4ec7-a2dc-be60ea6b9798"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A decision tree is a hierarchical tree-like structure where each internal node represents a decision based on the value of a feature, \\neach branch represents the outcome of that decision, and each leaf node represents a class label or a numerical value'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM\n",
        "\"\"\"A Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification tasks. It works by finding\n",
        "the hyperplane that best separates the data points into different classes in the feature space. The hyperplane is chosen such that it maximizes\n",
        "the margin, which is the distance between the hyperplane and the closest data points from each class, known as support vectors.\"\"\""
      ],
      "metadata": {
        "id": "Mm4CfXjXYzhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMiT26BWYzrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4SooJQOYzyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}